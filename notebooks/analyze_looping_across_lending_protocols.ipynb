{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This Jupyter Notebook aims to analyze user behavior across different lending protocols, focusing on how users interact with various tokens as collateral and debt. Specifically, we will investigate the looping behavior of users, where assets are borrowed on one protocol and then deposited as collateral in another protocol. This analysis will help us understand the extent and impact of such behaviors on the lending ecosystem.\n",
    "\n",
    "# Objectives\n",
    "### Load the Data\n",
    "\n",
    "- We will load loan data for multiple lending protocols from Google Cloud Storage. The datasets contain detailed information about users, their collateral, and debt across different protocols.\n",
    "- The data loading process will be implemented flexibly to allow easy switching between data sources (e.g., from cloud storage to a local database).\n",
    "\n",
    "### Visualize User Behavior\n",
    "- We will create visualizations to track the behavior of individual users across lending protocols, focusing on specific tokens such as \"ETH\", \"wBTC\", \"USDC\", \"DAI\", \"USDT\", \"wstETH\", \"LORDS\", \"STRK\", \"UNO\", and \"ZEND\".\n",
    "- The visualizations will help answer several key questions:\n",
    "  - How many users have borrowed an asset on one protocol and deposited the asset as collateral in another protocol?\n",
    "  - How many users have completed a loop, i.e., deposited token X as collateral, borrowed token Y, deposited Y in another protocol, and borrowed X again?\n",
    "  - What is the total dollar amount of tokens involved in these loops? How much are the deposits multiplied?\n",
    "  - Which protocols are most subject to looping behavior? How do they compare on a per-token basis?\n",
    "\n",
    "# Analysis and Insights\n",
    "The analysis will not only address the predefined questions but also explore additional metrics and hypotheses that may arise during the investigation.\n",
    "Meaningful outputs and insights will be provided, documenting the findings and their implications for the lending protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From local Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display  # Only needed for Jupyter Notebook\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host='your_host',\n",
    "    user='your_username',\n",
    "    password='your_password',\n",
    "    dbname='loans_db'\n",
    ")\n",
    "\n",
    "# List of protocols (table names in the PostgreSQL database)\n",
    "protocols = [\"zklend\", \"nostra_alpha\", \"nostra_mainnet\", \"hashstack_v0\", \"hashstack_v1\"]\n",
    "\n",
    "for protocol in protocols:\n",
    "    print(f\"Processing {protocol}...\")\n",
    "    \n",
    "    # Query the data from the PostgreSQL database\n",
    "    query = f\"SELECT * FROM {protocol}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    pd.set_option('display.max_columns', None)  # Display all columns\n",
    "    pd.set_option('display.max_colwidth', None)  # Display full column width\n",
    "    pd.set_option('display.width', None)  # Adjust display width\n",
    "\n",
    "    # Display the first rows\n",
    "    display(df.head())\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display  # Only needed for Jupyter Notebook\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='your_host',\n",
    "    user='your_username',\n",
    "    password='your_password',\n",
    "    database='loans_db'\n",
    ")\n",
    "\n",
    "# List of protocols (table names in the MySQL database)\n",
    "protocols = [\"zklend\", \"nostra_alpha\", \"nostra_mainnet\", \"hashstack_v0\", \"hashstack_v1\"]\n",
    "\n",
    "for protocol in protocols:\n",
    "    print(f\"Processing {protocol}...\")\n",
    "    \n",
    "    # Query the data from the MySQL database\n",
    "    query = f\"SELECT * FROM {protocol}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    pd.set_option('display.max_columns', None)  # Display all columns\n",
    "    pd.set_option('display.max_colwidth', None)  # Display full column width\n",
    "    pd.set_option('display.width', None)  # Adjust display width\n",
    "\n",
    "    # Display the first rows\n",
    "    display(df.head())\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "\n",
    "# URLs of the loans files for all lending protocols\n",
    "parquet_urls = {\n",
    "    \"zklend\": \"https://storage.googleapis.com/derisk-persistent-state/zklend_data/loans.parquet\",\n",
    "    \"nostra_alpha\": \"https://storage.googleapis.com/derisk-persistent-state/nostra_alpha_data/loans.parquet\",\n",
    "    \"nostra_mainnet\": \"https://storage.googleapis.com/derisk-persistent-state/nostra_mainnet_data/loans.parquet\",\n",
    "    \"hashstack_v0\": \"https://storage.googleapis.com/derisk-persistent-state/hashstack_v0_data/loans.parquet\",\n",
    "    \"hashstack_v1\": \"https://storage.googleapis.com/derisk-persistent-state/hashstack_v1_data/loans.parquet\"\n",
    "}\n",
    "\n",
    "\n",
    "for protocol,url in parquet_urls.items():\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "    # Read the Parquet file into a Pandas DataFrame\n",
    "    with BytesIO(response.content) as f:\n",
    "        table = pq.read_table(f)\n",
    "        df = table.to_pandas()\n",
    "\n",
    "    pd.set_option('display.max_columns', None)  # Display all columns\n",
    "    pd.set_option('display.max_colwidth', None)  # Display full column width\n",
    "    pd.set_option('display.width', None)  # Adjust display width\n",
    "\n",
    "\n",
    "    # Display the first rows\n",
    "    display(df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
